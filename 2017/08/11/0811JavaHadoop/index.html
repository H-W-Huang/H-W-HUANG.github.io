<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>使用Java对HDFS进行文件操作 | HWHuang的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="主要的API在Java中，涉及到HDFS文件操作的API主要有以下几个：  FileSystem FSDataOutputStream FSDataInputStream Path Configuration  IOUtils FileSystemFileSytem的全限定名为org.apache.hadoop.fs.FileSystem。org.apache.hadoop.fs.FileSyst">
<meta name="keywords" content="分布式系统,HDFS">
<meta property="og:type" content="article">
<meta property="og:title" content="使用Java对HDFS进行文件操作">
<meta property="og:url" content="http://yoursite.com/2017/08/11/0811JavaHadoop/index.html">
<meta property="og:site_name" content="HWHuang的博客">
<meta property="og:description" content="主要的API在Java中，涉及到HDFS文件操作的API主要有以下几个：  FileSystem FSDataOutputStream FSDataInputStream Path Configuration  IOUtils FileSystemFileSytem的全限定名为org.apache.hadoop.fs.FileSystem。org.apache.hadoop.fs.FileSyst">
<meta property="og:updated_time" content="2017-08-11T11:38:48.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="使用Java对HDFS进行文件操作">
<meta name="twitter:description" content="主要的API在Java中，涉及到HDFS文件操作的API主要有以下几个：  FileSystem FSDataOutputStream FSDataInputStream Path Configuration  IOUtils FileSystemFileSytem的全限定名为org.apache.hadoop.fs.FileSystem。org.apache.hadoop.fs.FileSyst">
  
    <link rel="alternate" href="/atom.xml" title="HWHuang的博客" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css">
  

</head>

<body>
  <nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="/index.html">Home</a></li>
        
          <li><a class=""
                 href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">HWHuang的博客</h1>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          <article id="post-0811JavaHadoop" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 class="article-title" itemprop="name">
      使用Java对HDFS进行文件操作
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2017/08/11/0811JavaHadoop/" class="article-date"><time datetime="2017-08-11T11:38:25.000Z" itemprop="datePublished">2017-08-11</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/大数据/">大数据</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="主要的API"><a href="#主要的API" class="headerlink" title="主要的API"></a>主要的API</h2><pre><code>在Java中，涉及到HDFS文件操作的API主要有以下几个：
</code></pre><ol>
<li>FileSystem</li>
<li>FSDataOutputStream</li>
<li>FSDataInputStream</li>
<li>Path</li>
<li>Configuration </li>
<li><p>IOUtils</p>
<h3 id="FileSystem"><a href="#FileSystem" class="headerlink" title="FileSystem"></a>FileSystem</h3><p>FileSytem的全限定名为<code>org.apache.hadoop.fs.FileSystem</code>。<br><code>org.apache.hadoop.fs.FileSystem</code>是在分布式环境中<strong>访问和管理HDFS中的文件/目录的通用类</strong>。<br>文件内容以多个大尺寸块（64M）的形式存储在datanode中，namenode中记录了这些块的信息和文件的元信息。<br>FileSystem可以读或者<strong>按块的顺序流式</strong>的访问。<br>FileSystem首先从NameNode中得到块的信息，然后<strong>一个接一个</strong>的读。 ~它打开第一个块，它将读完关闭后才访问下一块~ 。<br>HDFS的复制块带来了更高的可靠性和可扩展性。如果client是数据节点中的一个，它将先访问本地，如果失败的话，它才会到集群的其他节点去访问。</p>
<p><code>FileSystem</code>使用<code>FSDataOutputStream</code> 及<code>FSDataInputStream</code>来读写流的内容。Hadoop提供了多种FileSystem的实现：</p>
</li>
</ol>
<ul>
<li>DistributedFileSystem（DFS）：在分布式的环境中，访问HDFS文件</li>
<li>LocalFileSystem:在本地系统中访问HDFS文件</li>
<li>FTPFileSystem：访问HDFS文件的FTP客户端</li>
<li>WebHdfsFileSystem：通过web接口访问HDFS文件。</li>
</ul>
<h4 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h4><p>FileSystem 的常用操作和相关方法：</p>
<ol>
<li>创建文件<ul>
<li><code>booleancreateNewFile(Path f )</code><ul>
<li><strong>不会覆盖</strong>已有文件</li>
<li>创建成功返回true,失败返回false<br>• <code>FSDataOutputStreamcreate(Path f)</code><br>• <strong>覆盖</strong>已有文件<br>• 创建文件并返回输出流<br>• <code>FSDataOutputStreamcreate(Path f,booleanoverwrite)</code><br>• 创建文件并返回输出流<br>• <code>FSDataOutputStreamcreate(Path f,boolean overwrite,int buffer)</code><br>• <code>FSDataOutputStreamcreate(Path f,boolean overwrite,int buffer,short replication,long blockSize)</code></li>
</ul>
</li>
</ul>
</li>
<li>打开文件<ul>
<li><code>FSDataInputStreamopen(Pathf)</code></li>
<li><code>FSDataInputStreamopen(Pathf,intbufferSize)</code><ul>
<li>返回输入流</li>
<li>如果文件不存在会抛出异常</li>
<li>不指定bufferSize时,会从Configuration中读取 io.file.buffer.size,默认为4096字节</li>
</ul>
</li>
</ul>
</li>
<li>文件追加<br>• <code>FSDataOutputStream append(Path f)</code><br>• <code>FSDataOutputStream append(Path f, int bufferSize)</code><br>   • 块不足64M时,会补足到64M<br>   • 块达到64M之前,该块不可见,ls看不到该块新增的大小,也无 法读取<br>   • 不能同时多个writer追加同一个文件</li>
<li>从本地拷贝文件到HDFS<ul>
<li><code>void copyFromLocalFile (Path src, Path dst)</code></li>
<li><code>void moveFromLocalFile (Path src, Path dst)</code></li>
</ul>
</li>
<li>从HDFS拷贝文件到本地<ul>
<li><code>void copyToLocalFile(boolean delsrc,Path src,Path dst)</code></li>
<li><code>void moveToLocalFile (Path src, Path dst)</code></li>
</ul>
</li>
<li>创建目录<ul>
<li>boolean mkdirs (Path f)<br>• boolean mkdirs (Path f, FsPermission permission)<br>• static boolean mkdirs (FileSystem fs, Path dir, FsPermission permission)<br>• 支持多级目录同时创建 (类似mkdir -p)<br>• 默认权限是755<br>• 成功返回true</li>
</ul>
</li>
<li>删除及重命名<ul>
<li><code>boolean delete (Path f, boolean recursive)</code></li>
<li><code>boolean deleteOnExit (f)</code> 当关闭FileSystem时,才会删除</li>
</ul>
</li>
<li>获取文件或目录信息<ul>
<li>FileStatus[ ] listStatus (Path f, PathFilter filter)<br>• FileStatus[ ] listStatus (Path[ ] dir, PathFilter filter)<br>FileStatus信息包括:</li>
<li>绝对路径</li>
<li>文件大小(单位:字节)</li>
<li>文件访问时间</li>
<li>块大小、复制份数</li>
<li>文件所属用户、组、访问权限</li>
</ul>
</li>
<li>设置文件或目录属性<ul>
<li>void setOwner (Path p, String username, String groupname)<ul>
<li>设置文件或目录所属用户及组</li>
<li>参数p指定文件或目录</li>
<li>参数username,设置此文件或目录的所属用户 – 只返回列出指定目录下的文件或目录信息<br>• void setPermission (Path p, FsPermission permission)<br>• 设置文件或目录权限<br>• 参数p指定文件或目录<br>• 参数permission,指定权限,权限同linux权限雷同<br>• void setReplication (Path f, short replication)<br>• 设置文件复制份数<br>• 参数f指定文件<br>• 参数replication指定复制份数</li>
</ul>
</li>
</ul>
</li>
<li>获取文件或目录信息<ul>
<li>void setTimes (Path f, long mtime, long atime)<br>设置文件的修改及访问时间</li>
</ul>
</li>
</ol>
<h3 id="FSDataOutputStream"><a href="#FSDataOutputStream" class="headerlink" title="FSDataOutputStream"></a>FSDataOutputStream</h3><pre><code>FSDataOutputStream的全限定名是`org.apache.hadoop.fs.FSDataOutputStream`。
使用Java向HDFS**写入数据**时需要用到的流。
</code></pre><h3 id="FSDataInputStream"><a href="#FSDataInputStream" class="headerlink" title="FSDataInputStream"></a>FSDataInputStream</h3><pre><code>FSDataInputStream的全限定名是`org.apache.hadoop.fs. FSDataInputStream `。
使用Java向HDFS**读取数据**时需要用到的流。
</code></pre><h3 id="Path"><a href="#Path" class="headerlink" title="Path"></a>Path</h3><pre><code>Path的全限定名为`org.apache.hadoop.fs.Path`
用来封装HDFS的路径。
</code></pre><h4 id="常用的方法"><a href="#常用的方法" class="headerlink" title="常用的方法"></a>常用的方法</h4><p>Path的常有方法有：</p>
<ol>
<li><code>int depth()</code>：返回路径的深度</li>
<li><code>String getName()</code>： 返回路径上最后的资源名称</li>
<li><code>Path getParent()</code>：返回父目录，如果已是根目录则返回null</li>
<li><code>Path suffix(String suffix)</code>：参数suffix给Path增加后缀，返回加完后缀的Path实例；</li>
<li><code>getFileSystem (Configuration conf)</code>：返回该Path所属的文件系统实例</li>
</ol>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><pre><code>Configuration全限定名为
</code></pre><p><code>org.apache.hadoop.conf. Configuration</code>。<br>​<br>Configuration对配置文件的读取顺序：先加载缺省配置文件，再加载用户定义的配置文件；且对于每一个文件只加载一次：第一个在classpath出现的（这个和Linux系统上在匹配命令时候的逻辑是一样的）</p>
<p><em>classpath的目录顺序:</em></p>
<ol>
<li>$HADOOP_CONF_DIR</li>
<li>$JAVA_HOME/lib/tools.jar 如果$HADOOP_HOME目录下有build目录，则添加build下各子目录</li>
<li>$HADOOP_HOME/hadoop-core-*.jar</li>
<li>$HADOOP_HOME/lib/*.jar</li>
<li>用户在hadoop-env.sh中定义的$HADOOP_CLASS_PATH</li>
<li>当前作为hadoop jar …参数提交的JAR包</li>
</ol>
<h4 id="常用方法-1"><a href="#常用方法-1" class="headerlink" title="常用方法"></a>常用方法</h4><pre><code>Configuration的常用方法有:
</code></pre><ol>
<li>static void addDefaultResource(String name)</li>
<li>void addResource(InputStream in)</li>
<li>void addResource (Path file)  本地文件</li>
<li>void addResource(String name)  classpath中的文件</li>
<li>void addResource (URL url)void set(String name, String value)</li>
<li>void setBoolean(String name, boolean value)</li>
<li>void setInt(String name, String value)</li>
<li>void setLong(String name, long value)</li>
<li>void setFloat(String name, float value)</li>
<li>void setIfUnset(String name, String value)</li>
<li>void setBooleanIfUnset(String name, boolean value)</li>
<li>String get(String name)</li>
<li>boolean getBoolean(String name, boolean defaultValue)</li>
</ol>
<h3 id="IOUtils"><a href="#IOUtils" class="headerlink" title="IOUtils"></a>IOUtils</h3><pre><code>IOUtils的全限定名是`org.apache.hadoop.fs. IOUtils `。
IOUtils是一个I/O帮助类,提供的都是静态方法,不需要实例化。
</code></pre><h4 id="常用方法-2"><a href="#常用方法-2" class="headerlink" title="常用方法"></a>常用方法</h4><p>IOUtils的常用方法有：</p>
<ul>
<li>public static void copyBytes (InputStream in , outputStream out,<br>Configuration conf)<br>• public static void copyBytes (InputStream in , outputStream out, Configuration conf, boolean close)</li>
</ul>
<h2 id="开发基本步骤"><a href="#开发基本步骤" class="headerlink" title="开发基本步骤"></a>开发基本步骤</h2><p>使用Java在HDFS上的基本开发步骤如下：</p>
<ol>
<li>实例化<code>Configuration</code></li>
<li>实例化<code>FileSystem</code><ol>
<li>获取相关Stream进行文件／目录操作</li>
</ol>
</li>
</ol>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/11/0811JavaHadoop/" data-id="cj68mys7f0006shjobsogejwj" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/">HDFS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式系统/">分布式系统</a></li></ul>


    </footer>
  </div>
  
    
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  <li role="presentation">
    <a href="/2017/08/11/0811HadoopIO/" id="article-nav-older" class="article-nav-link-wrap">
      <i class="fa fa-chevron-left pull-left"></i>
      <span class="article-nav-link-title">Hadoop IO操作</span>
    </a>
  </li>
  
  
</ul>


  
</article>




        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p></p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/大数据/">大数据</a><span class="sidebar-module-list-count">6</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/HDFS/">HDFS</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/分布式系统/">分布式系统</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/大数据/">大数据</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/分布式系统/" style="font-size: 20px;">分布式系统</a> <a href="/tags/大数据/" style="font-size: 10px;">大数据</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/08/">August 2017</a><span class="sidebar-module-list-count">6</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2017/08/11/0811JavaHadoop/">使用Java对HDFS进行文件操作</a>
        </li>
      
        <li>
          <a href="/2017/08/11/0811HadoopIO/">Hadoop IO操作</a>
        </li>
      
        <li>
          <a href="/2017/08/10/0810HDFSreadwrite/">HDFS的读写策略</a>
        </li>
      
        <li>
          <a href="/2017/08/10/0810HDFoverview/">HDFS简述</a>
        </li>
      
        <li>
          <a href="/2017/08/07/cap/">cap理论</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2017 H.W.Huang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="/js/script.js"></script>

</body>
</html>
