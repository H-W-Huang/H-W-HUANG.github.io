<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>HWHuang的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="HWHuang的博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="HWHuang的博客">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HWHuang的博客">
  
    <link rel="alternate" href="/atom.xml" title="HWHuang的博客" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css">
  

</head>

<body>
  <nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class="active"
                 href="/index.html">Home</a></li>
        
          <li><a class=""
                 href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">HWHuang的博客</h1>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          
  
    <article id="post-0810HDFSreadwrite" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/10/0810HDFSreadwrite/">(no title)</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2017/08/10/0810HDFSreadwrite/" class="article-date"><time datetime="2017-08-10T13:20:30.000Z" itemprop="datePublished">2017-08-10</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="HDFS的读写策略"><a href="#HDFS的读写策略" class="headerlink" title="HDFS的读写策略"></a>HDFS的读写策略</h1><p>#软件学院实习/大数据</p>
<p>向HDFS读写数据的过程中涉及到以下几个部分：</p>
<ol>
<li>客户端节点</li>
<li>客户端节点上的JVM</li>
<li>数据节点</li>
<li>名称节点</li>
</ol>
<h2 id="从HDFS读取数据"><a href="#从HDFS读取数据" class="headerlink" title="从HDFS读取数据"></a>从HDFS读取数据</h2><p><img src="./images/0810/a_client_reading_data_from_HDFS.png" alt=""><br>​<br>流程如下：</p>
<ol>
<li>客户端回调用FileSystem的实例<code>DistributedFileSystem</code>的open方法，获得这个文件的<strong>输入流</strong>；</li>
<li>以RPC的方式调用名称节点，以确定文件开头部分块的位置（包括副本的位置，按照与客户端的距离来排序），</li>
<li>客户端按照就近原则，调用输入流的read方法从最近的DataNode读取数据， 若客户端本身就是一个数据节点，则直接从节点上读取（期间将操作日志发送给NameNode）；</li>
<li>客户端读取到数据块末端，将关闭与这个DataNode 的连接，然后<strong>重新查找</strong>下一个数据块。</li>
<li>重复2-4直到当客户端读取完成，<code>DFSInputStream</code>将被关闭；</li>
</ol>
<h2 id="向HDFS写数据"><a href="#向HDFS写数据" class="headerlink" title="向HDFS写数据"></a>向HDFS写数据</h2><p><img src="./images/0810/a_client_writing_data_to_HDFS.png" alt=""></p>
<ol>
<li>客户端通过在<code>DistributedFileSystem</code>调用<code>create</code>方法来创建文件；</li>
<li><code>DistributedFileSystem</code>的一个RPC调用NameNode，在文件系统的密码<strong>命名空间</strong>中创建一个新文件；NameNode 将通过一些检查，比如 ~文件是否存在~，客户端 ~是否拥有创建权限~ 等;通过检查之后，在NameNode 添加文件信息。注意，因为此时文件没有数据，所以<strong>NameNode 上也没有文件数据块的信息</strong>。</li>
<li>创建结束之后，HDFS会返回一个输出流 DFSDataOutputStream 给客户端；</li>
<li>客户端调用输出流DFSDataOutputStream的write方法向HDFS 中对应的文件写入数据。</li>
<li>数据首先会被<strong>分包</strong>，这些分包会写人一个<strong>输出流的内部队列</strong> Data 队列中， ~接收完数据分包，输出流DFSDataOutputStream会向NameNode申请保存文件和副本数据块的若干个DataNode ， 这若干个DataNode 会形成一个数据传输管道。~ DFSDataOutputStream 将数据传输给距离上最短的DataNode ，这个DataNode 接收到数据包之后会传给下一个DataNode 。 ~数据在各DataNode之间通过管道流动，而不是全部由输出流分发~， 以减少传输开销。</li>
<li>因为各DataNode位于不同机器上，数据需要通过网络发送，所以，为了保证所有DataNode 的数据都是准确的， ~接收到数据的 DataNode 要向<strong>发送者</strong>发送确认包(ACK Packet )~ 。对于某个数据块，只有当DFSDataOutputStream 收到了所有DataNode 的正确ACK，才能确认传输结束。DFSDataOutputStream 内部专 门维护了一个<strong>等待ACK 队列</strong>，这一队列保存已经进入管道传输数据、但是并未被完全确认的数据包。</li>
<li>重复4-6，DFSDataInputStream 继续等待直到所有数据写入完毕并<strong>被确认</strong>后，调用<code>close</code>关闭流，调用<code>complete</code>方法通知NameNode 文件写入完成。NameNode 接收到complete消息之后， ~等待相应数量的副本写入完毕后~， 告知客户端。</li>
</ol>
<p><em>数据流列表形成一个管线。</em><br><em>一个包只有在被管线中的<strong>所有节点</strong>确认后才会被移出确认队列</em></p>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/10/0810HDFSreadwrite/" data-id="cj66hb35b0000g9joyb3vmsk4" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-0810HDFoverview" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/10/0810HDFoverview/">(no title)</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2017/08/10/0810HDFoverview/" class="article-date"><time datetime="2017-08-10T13:20:30.000Z" itemprop="datePublished">2017-08-10</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="HDFS简述"><a href="#HDFS简述" class="headerlink" title="HDFS简述"></a>HDFS简述</h1><p>#软件学院实习/大数据</p>
<ol>
<li>简介hdfs架构</li>
<li>read write的策略</li>
</ol>
<p>工作原理、工作流程</p>
<h2 id="什么是HDFS"><a href="#什么是HDFS" class="headerlink" title="什么是HDFS"></a>什么是HDFS</h2><pre><code>HDFS是Hadoop的一个分布式文件系统 (Hadoop Distributed File System)。对外部客户机而言,HDFS 就像一个传统的分级文件系统。可以创建、删除、移动或重命名文件,等等。
HDFS在Hadoop框架中所处的位置如下图所示：
</code></pre><p><img src="./images/0810/Hframework.tiff" alt=""></p>
<p><em>关于文件系统</em></p>
<blockquote>
<pre><code>文件系统由三部分组成:与**文件管理有关软件**、 **被管理文件**以及**实施文件管理所需数据结构**。常见的有 Explorer、Total Commander在每台存储设 备里有很多被 管理文件如通用结构, 由超级块、节 点、数据块、 目录块、间接 块组成。  
从系统角度来看,文件系统是对文件存储器空 间进行组织和分配,负责文件存储并对存入的 文件进行保护和检索的系统。  
</code></pre></blockquote>
<h2 id="HDFS所能提供的"><a href="#HDFS所能提供的" class="headerlink" title="HDFS所能提供的"></a>HDFS所能提供的</h2><h3 id="大规模数据分布存储能力"><a href="#大规模数据分布存储能力" class="headerlink" title="大规模数据分布存储能力"></a>大规模数据分布存储能力</h3><pre><code>Hadoopj能够将超大的数据分块存储到不同的分区上，从而实现存储超大数据的功能。
</code></pre><h3 id="高并发访问能力"><a href="#高并发访问能力" class="headerlink" title="高并发访问能力"></a>高并发访问能力</h3><p><img src="check.tiff" alt=""><br>    数据存在于多个节点上，读取的时候可以并发读取）</p>
<h3 id="流式文件访问-提供简单的一致性模型"><a href="#流式文件访问-提供简单的一致性模型" class="headerlink" title="流式文件访问,提供简单的一致性模型"></a>流式文件访问,提供简单的一致性模型</h3><pre><code>DFS是用**流处理方式**处理文件, ~每个文件在系统里都能找到它的本地化映像~,所以对于用户来说,别管文件是什么格式的,也不用在意被分到哪里,只管从DFS里取出就可以了。
一次写入,多次读取。 ~数据源通常由源生成或从数据源直接复制而来,接着长时间在此数据集上进行各类分析~,大数据不需要搬来搬去。
</code></pre><h3 id="强大的容错能力（冗余存储）"><a href="#强大的容错能力（冗余存储）" class="headerlink" title="强大的容错能力（冗余存储）"></a>强大的容错能力（冗余存储）</h3><p><img src="check.tiff" alt=""><br>    每个分片文件需要分片服务器校验。</p>
<pre><code> 文件分布后调用会效率很低 吗? 文件分布处理过程丢失了怎 么办?文件种类很多到底分到哪好?
HDFS采用分片冗余，本地校验。

数据冗余式存储, ~直接将多份的分片文件交给分片后的存储服务器去校验~ 。
</code></pre><p><img src="redundency.tiff" alt=""><br>    冗余后的分片文件还有个额外功能, ~只要冗余的分片文件中有一份是完整的,经过多次协同调整后,其他分片文件也将完整~ 。（自动修正能力）</p>
<h2 id="HDFS的架构"><a href="#HDFS的架构" class="headerlink" title="HDFS的架构"></a>HDFS的架构</h2><pre><code>在HDFS这个分布式的文件系统中，存在着**两种节点**，DataNode和NameNode。
一个HDFS集群是由**一个**NameNode和**一定数目**的DataNode组成。
</code></pre><h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><pre><code>NameNode是一个主服务器,用来 ~管理整个 文件系统的命名空间和元数据~,以及 ~处理来自外界的文件访问请求~ 。NameNode 保存了文件系统的三种元数据：
</code></pre><p>• 命名空间, 即<strong>整个分布式文件系统的目录结构</strong>；<br>• 数据块与文件名的映射表；<br>• 每个数据块副本的位置信息,每一个数据块默认有3 个副本；<br>（一言蔽之，DataNode用来<strong>管理客户端访问</strong>，<strong>管理数据</strong>）</p>
<pre><code>稍微具体地说，即：
Namenode执行文件系统的名字空间操作，比如**打开**、**关闭**、**重命名**文件或目录。它也负责**确定数据块到具体Datanode节点的映射**。
</code></pre><h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><pre><code>稍微具体地说，即：
DataNode 负责处理文件系统用户具体的数 据读写请求,同时也可以处理NameNode 对数据块的创建、删除副本的指令。
</code></pre><h3 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h3><pre><code>HFDS的文件以**块**作为基本单位，默认大小设为64M字节。
HDFS将一个文件分为一个或数个块来存储。
</code></pre><p>使用数据块有以下的优点：</p>
<ol>
<li>当一个文件大于集群中任意一个磁盘的时候,文件系统可以充分利用集群中所 有的磁盘；</li>
<li>管理块使底层的存储子系统相对简单 ；</li>
<li>块更加适合备份,从而为容错和高可用性的实现带来方便；</li>
<li><p>采用块方式,实现了名字与位置的分离,实现了的存储位置的独立性；</p>
<p>上述优点的<strong>容错</strong>体现在块的<strong>冗余备份</strong>上，简单说来如下：</p>
</li>
</ol>
<ul>
<li>每个块在集群上会存储多 份(replica)，默认是三份；</li>
<li>某个块的所有备份都是同一个ID，这样一来对于块的管理变很便利了，不需要专门去记录某一块是那一份数据的；</li>
<li><p>系统可以根据机架的配置自动分配备份位置；也就是说，某一个数据块存于某个机架上的节点上，那么另外的几份备份会被存在另外的机架的两个节点上；</p>
<p>此外，在关于数据校验的设计上，每个块会在本地文件系统产生两个文件,一个是<strong>实际的数据文件</strong>,另一个是<strong>块的附加信息文件,其中包括数据的校验和</strong>。</p>
</li>
</ul>
<h3 id="元数据-－－-NameNode的账目"><a href="#元数据-－－-NameNode的账目" class="headerlink" title="元数据  －－  NameNode的账目"></a>元数据  －－  NameNode的账目</h3><p>HDFS的元数据包括：</p>
<ul>
<li>文件系统目录树信息<br>• 文件名,目录名<br>• 文件和目录的从属关系<br>• 文件和目录的大小,创建及最后访问时间<br>• 权限</li>
<li>文件和块的对应关系<br>• 文件由哪些块组成</li>
<li>块的存放位置<br>• 机器名,块ID</li>
</ul>
<h4 id="HDFS对元数据和实际数据的存储方法"><a href="#HDFS对元数据和实际数据的存储方法" class="headerlink" title="HDFS对元数据和实际数据的存储方法"></a>HDFS对元数据和实际数据的存储方法</h4><p>元数据存储在一台指定的服务器上，而且是存在<strong>内存</strong>中的(<strong>NameNode</strong>)<br>实际数据储存在集群的其他机器的本地文件系统中 (<strong>DataNode</strong>)</p>
<h2 id="访问HDFS的方法"><a href="#访问HDFS的方法" class="headerlink" title="访问HDFS的方法"></a>访问HDFS的方法</h2><pre><code>采用命令行客户端，或者使用相关的API客户端。
</code></pre>
      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/10/0810HDFoverview/" data-id="cj66hb35j0002g9jogaronoor" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-cap" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/07/cap/">cap理论</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2017/08/07/cap/" class="article-date"><time datetime="2017-08-07T13:03:25.000Z" itemprop="datePublished">2017-08-07</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/大数据/">大数据</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="CAP理论概述"><a href="#CAP理论概述" class="headerlink" title="CAP理论概述"></a>CAP理论概述</h3><p>C: Consistency 一致性<br>A: Availability 可用性<br>P: Partition tolerance 分区容错性</p>
<p>该理论认为，一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这<strong>三项中的两项</strong>。</p>
<p>（数据）一致性：<br>all nodes see the same data at the same time，即更新操作成功并返回客户端完成后，<strong>所有节点</strong>在<strong>同一时间</strong>的<strong>数据完全一致</strong></p>
<p> （服务）可用性：<br>Reads and writes always succeed，也就是说，服务必须<strong>一直可用</strong>，而且是正常响应时间。</p>
<p>（系统）分区容错性：<br>the system continues to operate despite arbitrary message loss or failure of part of the system，即分布式系统在~遇到某节点或网络分区故障~的时候，仍然能够对外提供满足<strong>一致性</strong>和<strong>可用性</strong>的服务。</p>
<p>参考：<a href="http://www.hollischuang.com/archives/666" target="_blank" rel="external">分布式系统的CAP理论-HollisChuang’s Blog</a></p>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/07/cap/" data-id="cj66hb35g0001g9jo0qz78633" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式系统/">分布式系统</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-test" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/07/test/">第一天作业笔记</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2017/08/07/test/" class="article-date"><time datetime="2017-08-07T10:42:19.000Z" itemprop="datePublished">2017-08-07</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/大数据/">大数据</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="数据的单位：-K-M-G-T-P-E-Z-Y-D-N"><a href="#数据的单位：-K-M-G-T-P-E-Z-Y-D-N" class="headerlink" title="数据的单位： K M G T P E Z Y D N"></a>数据的单位： K M G T P E Z Y D N</h3><p>大数据设计到的数据单位有下：<br>B ，KB，MB，GB，TB，PB，EB，ZB，YB<br>其中，从左到右，单位之间的关系如下：<br>1B     = 8 bites<br>1KB    =  1024B<br>1MB=  1024KB<br>1GB    =  1024MB<br>1TB    =  1024GB<br>1PB    =  1024TB<br>1EB    =  1024PB<br>1ZB    =  1024EB<br>1YB    =  1024ZB<br>1DB    =  1024YB<br>1NB    =  1024DB</p>
<hr>
<h3 id="什么是大数据？"><a href="#什么是大数据？" class="headerlink" title="什么是大数据？"></a>什么是大数据？</h3><blockquote>
<p>Big data is a term for <strong>data sets</strong> that are ~so large or complex that traditional data processing application software is inadequate to deal with them~.<br><a href="http://www.webopedia.com/TERM/S/structured_data.html" target="_blank" rel="external">What is Structured Data? Webopedia Definition</a><br>根据维基百科的对大数据的定义，可以看到大数据是一个关于数据集的术语。<br>本身足够大或者足够复杂以至于传统的数据处理应用软件不足够处理它们。</p>
</blockquote>
<ol>
<li>数据类型： 结构化的， 非结构化的</li>
</ol>
<p>结构化数据结构:</p>
<blockquote>
<p>Structured data refers to any data that <strong>resides in a fixed field</strong> within a record or file. This includes data contained in <strong>relational databases</strong> and <strong>spreadsheets</strong>.<br>​    也就是说，结构化的数据是行数据，存储在数据库里,可以用二维表结构来逻辑表达实现的数据。</p>
</blockquote>
<p>非结构话的数据结构:</p>
<blockquote>
<p>Unstructured data is all those things that <strong>can’t be so readily classified and fit into a neat box</strong>: photos and graphic images, videos, streaming instrument data, webpages, PDF files, PowerPoint presentations, emails, blog entries, wikis and word processing documents.<br>​    也即是说，非结构化的数据大多指的是办公文档、文本、图片、XML、HTML、各类报表、图像和音频/视频信息等等数据。</p>
</blockquote>
<hr>
<h3 id="大数据的4个V"><a href="#大数据的4个V" class="headerlink" title="大数据的4个V"></a>大数据的4个V</h3><p>大数据的四个V包括：</p>
<ol>
<li>Velocity：实现<strong>快速的数据流传</strong></li>
<li>Variety： 具有<strong>多样的数据类型</strong></li>
<li>Volume： 存有<strong>海量的数据规模</strong>（TB，PB，EB级别）</li>
<li>Value：存在着<strong>巨大的价值</strong></li>
</ol>
<hr>
<h3 id="大数据的工作流程"><a href="#大数据的工作流程" class="headerlink" title="大数据的工作流程"></a>大数据的工作流程</h3><ul>
<li>采集数据<br>数据的类型多种多样。可以是各大网络上每天产生的数据，可以是各种传感器所产生的数据，可以是科研或者实验日志。<br>采集的方法一般有以下几种：<ul>
<li>系统日志采集方法，即在系统内部使用专用的数据采集工具来采集日志</li>
<li>网络数据采集方法：通过网络爬虫或者网站提供的API来获取数据。这种方法多用来收集非结构化数据；</li>
</ul>
</li>
<li>清洗数据ETL</li>
<li>ETL的概念<br> ETL表示<code>Extract Transform Load</code>，也就是抽取，转换，装载的过<br> 程，是构建<strong>数据仓库</strong>的一个重要环节；</li>
<li>数据清理<br> 数据清洗（data cleansing/data cleaning/data scrubing）是一个<strong>减少错误</strong>和<strong>不一致性</strong>、<strong>解决对象识别</strong>的过程。<br> 也就是说，在数据清理结果，将通过ETL处理过程，减少原数据的错误和不一致型，从业有利于下一阶段的分析；</li>
<li>分析数据<br>就是对清洗过后的数据进行分析和挖掘。<br>利用分布式数据库，或者分布式计算集群来对存储于其内的海量数据进行普通的分析和分类汇总等，以满足大多数常见的分析需求。<br>一般来说，本阶段会有<strong>数据量大</strong>，其对<strong>系统资源，特别是I/O</strong>会有极大的占用等问题。</li>
<li>呈现<br>也就是将分析后的数据进行呈现。<br>一般采用各种可视化工具，将数据转化为图表等形式进行呈现。<br>当前可用的可视化工具有：Tableau，ChartBlocks，Datawrapper，Plotly，RAW等等；</li>
</ul>
<hr>
<h3 id="计算模式"><a href="#计算模式" class="headerlink" title="计算模式"></a>计算模式</h3><ul>
<li>批处理<br>批处理就是对某对象进行批量的处理。<br>在大数据处理中，最适合的批处理是<strong>MapReduce</strong>。<br>简单的讲，MapReduce对具有<strong>简单数据关系</strong>，<strong>易于划分</strong>的大规模数据采用<strong>分而治之</strong>的方式进行<strong>并行处理</strong>。本身是一个~单输入、两阶段( Map 和Reduce) 的数据处理过程~。</li>
<li>流计算<br>流计算对一定<strong>时间窗口内</strong>应用系统产生的新数据完成<strong>实时的计算</strong>，避免造成数据堆积和丢失。<br>流计算能够较好地解决MapReduce模型存在的延迟大的问题。<br>使用场景有：<br>统计网站中每一个页面，域名的点击次数<br>内部系统的运行监控（统计被监控服务器的运行状态）<br>记录最大值和最小值<br><a href="http://yangxiaowei.cn/wordpress/?p=551" target="_blank" rel="external">关于大数据下流计算的一些问题</a></li>
<li>迭代计算<br>迭代计算能够解决批量计算的难以迭代的缺陷，该计算模式通常用于处理大规模的科学计算。<br>相关的框架有：Apache Giraph，HaLoop，Twister等等。</li>
<li>交互式处理<br>特点：<ul>
<li>系统与操作人员以人机对话的方式<strong>一问一答</strong>；</li>
<li>操作人员提出请求,数据以对话的方式输入,系统便提供相应的数据或提示信息,引导操作人员<strong>逐步</strong>完成所需的操作,直至获得最后处理结果；</li>
<li>存储在系统中的数据文件<strong>能够被及时处理修改</strong>,同时处理<strong>结果可以立刻被使用</strong>；<br>典型系统：Dremel、spark</li>
</ul>
</li>
<li>图计算<br>“图计算”是以“<strong>图论</strong>”为基础的对现实世界的一种“图”结构的抽象表达，以及在这种数据结构上的计算模式。<br>引入图计算是因为图数据结构很好的表达了<strong>数据之间的关联性</strong>( dependencies between data )，关联性计算是大数据计算的核心——~通过获得数据的关联性，可以从噪音很多的海量数据中抽取有用的信息~。比如，通过为购物者之间的关系建模，就能很快找到口味相似的用户，并为之推荐商品；或者在社交网络中，通过传播关系发现意见领袖。<br>典型的系统包括Google 公司的Pregel 、Facebook Giraph 、Spark 下的GraphX；<br><a href="http://www.csdn.net/article/1970-01-01/2825748" target="_blank" rel="external">如何利用“图计算”实现大规模实时预测分析-CSDN.NET</a></li>
<li>内存计算<br>内存计算是以<strong>大数据为中心</strong>、依托计算机硬件的发展、依靠新型的软件体系结构,即,通过对体系结构及编程模型等进行重大革新,~将数据装入内存中处理,而尽量避免 I/O 操作的一种新型的以数据为中心~的并行计算模式.<a href="http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=5103&amp;journal_id=jos" target="_blank" rel="external">内存计算技术研究综述</a></li>
</ul>
<hr>
<h3 id="数据库类型："><a href="#数据库类型：" class="headerlink" title="数据库类型："></a>数据库类型：</h3><p><a href="http://www.jianshu.com/p/107c6b045245" target="_blank" rel="external">超全的数据库分类介绍 - 简书</a></p>
<ul>
<li>列存储（Column-oriented）数据库<br>列存储数据库将数据存储在<strong>列族</strong>中，一个列族存储<strong>经常被一起查询的相关数据</strong>，比如人类，我们经常会查询某个人的姓名和年龄，而不是薪资。这种情况下姓名和年龄会被放到一个列族中，薪资会被放到另一个列族中。<br>这种数据库通常用来应对分布式存储海量数据。<br>典型产品：Cassandra、HBase。</li>
<li>基于文档（mongoldb）<br>文档型数据库的灵感是来自于Lotus Notes办公软件，而且它同第一种键值数据库类似。该类型的数据模型是<strong>版本化的文档</strong>，<strong>半结构化的文档</strong>以<strong>特定的格式</strong>存储，比如JSON。~文档型数据库可以看作是键值数据库的升级版，允许之间嵌套键值~。而且文档型数据库比键值数据库的查询效率更高。<br>面向文档数据库会将数据以文档形式存储。~每个文档都是<strong>自包含</strong>的数据单元，是一系列数据项的集合。~每个数据项都有一个名词与对应值，值既可以是简单的数据类型，如字符串、数字和日期等；也可以是复杂的类型，如有序列表和关联对象。数据存储的<strong>最小单位</strong>是<strong>文档</strong>，同一个表中存储的文档属性可以是不同的，数据可以使用XML、JSON或JSONB等多种形式存储。<br>典型产品：MongoDB、CouchDB</li>
<li>基于内存<br>内存数据库是指一种将<strong>全部内容存放在内存</strong>中，而非传统数据库那样存放在外部存储器中的数据库。内存数据库指的是所有的数据访问控制都在内存中进行，这是与磁盘数据库相对而言的。<br>典型产品：Redis</li>
</ul>
<hr>
<h3 id="分布式系统（拜占庭将军问题）"><a href="#分布式系统（拜占庭将军问题）" class="headerlink" title="分布式系统（拜占庭将军问题）"></a>分布式系统（拜占庭将军问题）</h3><p>引用一下Distributed Systems Concepts and Design（Third Edition）中的一句话：<br>A distributed system is one in which components <strong>located at networked computers</strong> communicate and coordinate their actions <strong>only by passing messages</strong>。<br>从此得出两个要点：</p>
<ul>
<li>组件分布与网络计算机；</li>
<li>仅通过消息传递来通信和协调；</li>
</ul>
<p>在分布式系统中有一个著名的问题：拜占庭将军问题。<br>此处引用巴比特网的一边文章简单介绍：<br>有以下几个要点需要注意：</p>
<ul>
<li>问题假设了消息的信道是没有问题的（当考虑了信道是有问题的，则涉及到另一个问题了<strong>两军问题</strong>）；</li>
<li><strong>一致性</strong>和<strong>正确性</strong>是该问题的要求；</li>
<li>结论是：若叛徒数为m，当将军总数n至少为3m+1时，问题可解；</li>
</ul>
<p><a href="http://www.8btc.com/baizhantingjiangjun" target="_blank" rel="external">拜占庭将军问题深入探讨 | 巴比特</a></p>
<hr>
<h3 id="关于CDH"><a href="#关于CDH" class="headerlink" title="关于CDH"></a>关于CDH</h3><p>CDH全称为Cloudera’s Distribution Including Apache Hadoop。<br>CDH首先是100%开源，基于Apache协议。基于Apache Hadoop和相关projiect开发。可以做批量处理，交互式sql查询和及时查询，基于角色的权限控制。在企业中使用最广的hadoop分发版本。</p>
<p>CHD和Hadoop的关系类似于 Red Hat 之于Linux。</p>
<hr>
<h3 id="Hadoop技术栈"><a href="#Hadoop技术栈" class="headerlink" title="Hadoop技术栈"></a>Hadoop技术栈</h3><ol>
<li>hdfs<br>Hadoop的分布式文件系统，提供数据存储的功能。</li>
<li>mapreduce<br>Hadoop 的核心。是一个可以对大量数据进行分布式处理的软件框架，基于Map/Reduce技术。</li>
<li>hive<br>hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。<br><a href="https://baike.baidu.com/item/hive/67986" target="_blank" rel="external">hive（数据仓库工具）_百度百科</a></li>
<li>hbase<br>HBase是一个开源的非关系型分布式数据库（NoSQL），它参考了谷歌的BigTable建模，实现的编程语言为Java。它是Apache软件基金会Hadoop项目的一部分，运行于HDFS文件系统之上，为Hadoop提供类似于BigTable规模的服务。<br>用于改善<strong>数据的访问</strong>。<br><a href="https://www.bing.com/knows/search?q=hbase&amp;mkt=zh-cn" target="_blank" rel="external">hbase - Bing 网典</a></li>
<li>Sqoop<br>主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。<br>主要用于<strong>其他数据库</strong>和<strong>Hadoop中的数据库</strong>举行数据传输。</li>
<li>Zookeeper<br>zookeeper作为一个开源的分布式应用协调系统，已经用到了许多分布式项目中，用来完成<strong>统一命名服务</strong>、<strong>状态同步服务</strong>、<strong>集群管理</strong>、<strong>分布式应用配置项的管理</strong>等工作。<br>换句话说，Zookeeper主要用来对分布式项目进行管理。</li>
<li>Mahout<br>Mahout 是 Apache Software Foundation（ASF） 旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。<br><a href="https://baike.baidu.com/item/mahout" target="_blank" rel="external">mahout_百度百科</a></li>
</ol>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/07/test/" data-id="cj66hb35q0005g9jozl1t6440" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分布式系统/">分布式系统</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大数据/">大数据</a></li></ul>


    </footer>
  </div>
  
</article>



  




        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p></p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/大数据/">大数据</a><span class="sidebar-module-list-count">2</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/分布式系统/">分布式系统</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/大数据/">大数据</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="/tags/分布式系统/" style="font-size: 20px;">分布式系统</a> <a href="/tags/大数据/" style="font-size: 10px;">大数据</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/08/">August 2017</a><span class="sidebar-module-list-count">4</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2017/08/10/0810HDFSreadwrite/">(no title)</a>
        </li>
      
        <li>
          <a href="/2017/08/10/0810HDFoverview/">(no title)</a>
        </li>
      
        <li>
          <a href="/2017/08/07/cap/">cap理论</a>
        </li>
      
        <li>
          <a href="/2017/08/07/test/">第一天作业笔记</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2017 H.W.Huang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="/js/script.js"></script>

</body>
</html>
